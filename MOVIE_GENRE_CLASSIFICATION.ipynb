{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPML0UjJHaGMSRamfSd3X7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAJAD-52/CODSOFT/blob/main/MOVIE_GENRE_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F4OxC27JqHY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path='/content/train_data.txt'\n",
        "\n",
        "col = [\"ID\", \"TITLE\", \"GENRE\", \"DESCRIPTION\"]\n",
        "col2= [\"ID\", \"TITLE\", \"DESCRIPTION\"]\n",
        "data=pd.read_csv(path, sep=\":::\", names=col)\n",
        "\n",
        "path2 = '/content/test_data.txt'\n",
        "data2 = pd.read_csv(path2, sep=\":::\", names=col2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "54PWZVovNDyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text= text.lower()\n",
        "\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "  toknizes = word_tokenize(text)\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  token = [word for word in toknizes if word not in stop_words]\n",
        "\n",
        "  lem = WordNetLemmatizer()\n",
        "  lemtext = [lem.lemmatize(word) for word in token ]\n",
        "\n",
        "  # Join tokens back into a string\n",
        "  pretxt = ' '.join(lemtext)\n",
        "\n",
        "  return pretxt"
      ],
      "metadata": {
        "id": "Mu1pR58JQs9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocess_text function to the DESCRIPTION column\n",
        "data['DESCRIPTION'] = data['DESCRIPTION'].apply(preprocess)"
      ],
      "metadata": {
        "id": "EIxHj_JpT34M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2['DESCRIPTION'] = data2['DESCRIPTION'].apply(preprocess)"
      ],
      "metadata": {
        "id": "TytLBoIzgHPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "LYx5zqh0T-nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.head()"
      ],
      "metadata": {
        "id": "hGOCGHQIk_F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the original training dataset into train and test subsets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the train and test subsets\n",
        "print(\"Train subset shape:\", train_data.shape)\n",
        "print(\"Test subset shape:\", test_data.shape)\n",
        "\n",
        "Tfv = TfidfVectorizer(max_features=5000)\n",
        "Tfv.fit(train_data['DESCRIPTION'])\n"
      ],
      "metadata": {
        "id": "EWwJl79JXStP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the DESCRIPTION column into TF-IDF features\n",
        "X_train = Tfv.transform(train_data['DESCRIPTION'])"
      ],
      "metadata": {
        "id": "7luvQQ81ZMaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = Tfv.transform(test_data['DESCRIPTION'])"
      ],
      "metadata": {
        "id": "wuGf1VWtocdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "05YC9ptBaZUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "GCD9V0iWaj-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "LRC = LogisticRegression()\n",
        "\n",
        "# Train the model on the TF-IDF features and GENRE labels\n",
        "LRC.fit(X_train, train_data['GENRE'])\n"
      ],
      "metadata": {
        "id": "fjD6vsfXart1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the genre labels for the training data\n",
        "test_predictions = LRC.predict(X_test)\n",
        "\n",
        "test_predictions.shape"
      ],
      "metadata": {
        "id": "TgxJgQTWoNyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['GENRE'].shape"
      ],
      "metadata": {
        "id": "AStuANkdqUz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy of the model on the training data\n",
        "LRC_accuracy = accuracy_score(test_data['GENRE'], test_predictions)\n",
        "print(\"LRC Accuracy is:\", LRC_accuracy)"
      ],
      "metadata": {
        "id": "_3KBQAoTplDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "NB = MultinomialNB()\n",
        "#train\n",
        "NB.fit(X_train, train_data['GENRE'])\n",
        "#predict\n",
        "predict_NB = NB.predict(X_test)\n"
      ],
      "metadata": {
        "id": "3q_Y3VJvychL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NB_accuracy = accuracy_score(predict_NB, test_data['GENRE'])\n",
        "print(\"NB accurcy is :\", NB_accuracy)"
      ],
      "metadata": {
        "id": "Lb5empuuzpRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "SVC1 = SVC()\n",
        "SVC1.fit(X_train, train_data['GENRE'])\n",
        "preidct_svc = SVC1.predict(X_test)"
      ],
      "metadata": {
        "id": "1_y6dX-rolPJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}